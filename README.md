When public available data sets contain sensitive information about individuals, security measures are essentially.
[This paper](https://github.com/StefanHanisch/DifferentialPrivacy/blob/master/DifferentialPrivacyForDecisionTrees.pdf) provides an overview of traditional techniques with their corresponding weaknesses and introduces differential privacy as a mathematical substantiated framework to guarantee privacy. 
After a mathematical derivation, real world examples illustrate the technique and point out possible disadvantages.

To extract general relationships out of noisy data, machine learning algorithms are introduced with respect to the tradeoff between the number of queries and accurate results. 

Finally, an own implementation of a random private decision tree and forest is presented, applied on a real data set and compared with nonprivate decision trees and forests.